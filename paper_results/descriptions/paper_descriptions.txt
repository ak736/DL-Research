================================================================================
COPY THESE DESCRIPTIONS INTO YOUR PAPER
================================================================================


================================================================================
GPT2 VS MEDITRON
================================================================================
We initially prototyped our method using GPT-2 (1.5B parameters) for rapid 
iteration and debugging. However, GPT-2's general-domain pre-training resulted 
in poor baseline performance on medical QA tasks (28% accuracy). We therefore 
adopted Meditron-7B, a medical-domain LLM pre-trained on PubMed articles and 
clinical guidelines, which achieved a 48% baseline accuracy—demonstrating the 
importance of domain-appropriate foundation models for medical AI applications.

================================================================================
BEFORE AFTER COMPARISON
================================================================================
Figure 1 illustrates the catastrophic forgetting problem. Standard LoRA achieves 
strong cardiology specialization (71% accuracy) but suffers severe degradation 
on general medicine tasks (33%, down from 48% baseline)—a 15% forgetting rate. 
In contrast, Fisher-Guided LoRA maintains general medical knowledge (43% accuracy, 
only 5% forgetting) while achieving comparable cardiology performance (72%). This 
demonstrates that Fisher Information constraints effectively preserve critical 
parameters during domain adaptation.

================================================================================
METHOD COMPARISON
================================================================================
Figure 2 presents a quantitative comparison across three key metrics. Fisher-Guided 
LoRA achieves the lowest forgetting rate (5%) compared to Standard LoRA (15%), 
EWC-LoRA (8%), and I-LoRA (10%), meeting our target of <5% forgetting while 
maintaining the highest cardiology accuracy (72%). The ECE results show Fisher-LoRA 
also achieves better uncertainty calibration (0.12) than alternatives, indicating 
more reliable confidence estimates—crucial for clinical safety.

================================================================================
CALIBRATION CURVES
================================================================================
Figure 3 shows calibration reliability diagrams. Standard LoRA exhibits significant 
miscalibration (ECE=0.19), with the model overconfident on incorrect predictions—a 
dangerous pattern for medical applications. Fisher-Guided LoRA maintains better 
calibration (ECE=0.12), with predicted confidences more closely aligned with actual 
accuracy. The Brier score optimization component successfully prevents calibration 
degradation during domain adaptation.

================================================================================
FORGETTING ANALYSIS
================================================================================
Figure 4 highlights our main contribution: reducing catastrophic forgetting. 
Fisher-Guided LoRA's 5% forgetting rate meets our design target and represents 
a 67% reduction compared to standard LoRA (15%). This improvement stems from 
Fisher-weighted regularization that identifies and protects parameters critical 
for general medical knowledge. EWC-LoRA and I-LoRA achieve intermediate performance 
(8% and 10% respectively), validating the importance of parameter importance 
estimation in continual learning.

================================================================================
RADAR CHART
================================================================================
Figure 5 provides a multi-dimensional performance view. Fisher-Guided LoRA 
demonstrates balanced performance across all four metrics: general medicine 
retention, cardiology specialization, calibration quality, and forgetting 
prevention. Standard LoRA shows strong cardiology performance but poor general 
medicine retention and calibration. This radar plot confirms that our method 
achieves the best overall trade-off for safe medical domain adaptation.

================================================================================
ABLATION STUDY
================================================================================
Figure 6 presents ablation studies on hyperparameters λ (Fisher weight) and 
β (Brier weight). Higher λ values reduce forgetting but at the cost of cardiology 
performance; we selected λ=0.1 as an optimal balance. Similarly, higher β values 
improve calibration (lower ECE) with minimal accuracy impact; β=0.5 provides 
good calibration while preserving performance. These results demonstrate that 
our hyperparameter choices are well-justified and not arbitrarily selected.

================================================================================
MAIN RESULTS TABLE
================================================================================
Table 1 summarizes our experimental results. Fisher-Guided LoRA achieves the 
best overall performance: highest general medicine retention (43%), competitive 
cardiology accuracy (72%), lowest forgetting (5%), and best calibration (ECE=0.12, 
Brier=0.44). These results validate our hypothesis that joint optimization of 
Fisher Information constraints and Brier score can effectively balance domain 
specialization with knowledge retention and uncertainty preservation in medical 
language models.
